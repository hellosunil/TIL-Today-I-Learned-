{"cells":[{"cell_type":"code","source":["my_range = spark.range(1000).toDF('number')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b1df6f0c-aed2-4ffd-8e93-f021a65cc696","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["divisBy2 = my_range.where(\"number % 2 = 0\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bddd8290-fa59-43b9-a8ae-cb69326f4958","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["divisBy2.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ae431159-5acb-4f08-85d6-93aa82ad8cf1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[4]: 500","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[4]: 500"]}}],"execution_count":0},{"cell_type":"code","source":["flightData2015 = spark \\\n                    .read\\\n                    .option(\"inferSchema\", \"true\")\\\n                    .option(\"header\", \"true\")\\\n                    .csv(\"/databricks-datasets/definitive-guide/data/flight-data/csv/2015-summary.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"27ff6913-ff98-45fc-9214-142124f3fe80","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["flightData2015.take(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"573f1dbe-5806-475e-9d62-92cc2ced7684","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[6]: [Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[6]: [Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]"]}}],"execution_count":0},{"cell_type":"code","source":["flightData2015.sort(\"count\").explain()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"19321772-370a-41f8-a3eb-58f484cfb8e2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Sort [count#57 ASC NULLS FIRST], true, 0\n   +- Exchange rangepartitioning(count#57 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=92]\n      +- FileScan csv [DEST_COUNTRY_NAME#55,ORIGIN_COUNTRY_NAME#56,count#57] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/definitive-guide/data/flight-data/csv/2015-s..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Sort [count#57 ASC NULLS FIRST], true, 0\n   +- Exchange rangepartitioning(count#57 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=92]\n      +- FileScan csv [DEST_COUNTRY_NAME#55,ORIGIN_COUNTRY_NAME#56,count#57] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/definitive-guide/data/flight-data/csv/2015-s..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")\nflightData2015.sort(\"count\").take(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7e342db1-ed3c-472b-878e-190030b5405d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[8]: [Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[8]: [Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]"]}}],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\", \"10\")\nflightData2015.sort(\"count\").take(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0cfc99c2-6af5-4cd3-be79-04776b967ad4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[9]: [Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[9]: [Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]"]}}],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\", \"1\")\nflightData2015.sort(\"count\").take(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"205d28ca-8ec4-474f-be23-2261437e60d9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[10]: [Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[10]: [Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]"]}}],"execution_count":0},{"cell_type":"code","source":["# sql\n\nflightData2015.createOrReplaceTempView(\"flight_data_2015\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7c77075d-ab11-4f5c-80e3-d1cafa468de3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sqlWay = spark.sql(\"\"\"\n    select DEST_COUNTRY_NAME, count(1)\n    from flight_data_2015\n    group by DEST_COUNTRY_NAME\n\"\"\")\n\n\ndataFrameWay = flightData2015.groupBy(\"DEST_COUNTRY_NAME\").count()\n\n\n\nsqlWay.explain()\nprint(\"------------------------------\")\ndataFrameWay.explain()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85633258-82ca-4ddb-bef7-f71981165abd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[finalmerge_count(merge count#86L) AS count(1)#74L])\n   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#55, 1), ENSURE_REQUIREMENTS, [plan_id=132]\n      +- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[partial_count(1) AS count#86L])\n         +- FileScan csv [DEST_COUNTRY_NAME#55] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/definitive-guide/data/flight-data/csv/2015-s..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n\n\n------------------------------\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[finalmerge_count(merge count#88L) AS count(1)#81L])\n   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#55, 1), ENSURE_REQUIREMENTS, [plan_id=153]\n      +- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[partial_count(1) AS count#88L])\n         +- FileScan csv [DEST_COUNTRY_NAME#55] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/definitive-guide/data/flight-data/csv/2015-s..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[finalmerge_count(merge count#86L) AS count(1)#74L])\n   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#55, 1), ENSURE_REQUIREMENTS, [plan_id=132]\n      +- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[partial_count(1) AS count#86L])\n         +- FileScan csv [DEST_COUNTRY_NAME#55] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/definitive-guide/data/flight-data/csv/2015-s..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n\n\n------------------------------\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[finalmerge_count(merge count#88L) AS count(1)#81L])\n   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#55, 1), ENSURE_REQUIREMENTS, [plan_id=153]\n      +- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[partial_count(1) AS count#88L])\n         +- FileScan csv [DEST_COUNTRY_NAME#55] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/definitive-guide/data/flight-data/csv/2015-s..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"select max(count) from flight_data_2015\").take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"15facd50-118f-44e4-a2c2-ad13e9cfc623","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[13]: [Row(max(count)=370002)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[13]: [Row(max(count)=370002)]"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import max\n\nflightData2015.select(max(\"count\")).take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"72e742d2-e0cf-404b-83d2-7c0afde7d761","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[14]: [Row(max(count)=370002)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[14]: [Row(max(count)=370002)]"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import desc\n\nflightData2015\\\n    .groupBy(\"DEST_COUNTRY_NAME\")\\\n    .sum(\"count\")\\\n    .withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n    .sort(desc(\"destination_total\"))\\\n    .limit(5)\\\n    .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ebdb6d53-c10e-4289-8bdd-e9f6d44de68a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------------+-----------------+\n|DEST_COUNTRY_NAME|destination_total|\n+-----------------+-----------------+\n|    United States|           411352|\n|           Canada|             8399|\n|           Mexico|             7140|\n|   United Kingdom|             2025|\n|            Japan|             1548|\n+-----------------+-----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------------+-----------------+\n|DEST_COUNTRY_NAME|destination_total|\n+-----------------+-----------------+\n|    United States|           411352|\n|           Canada|             8399|\n|           Mexico|             7140|\n|   United Kingdom|             2025|\n|            Japan|             1548|\n+-----------------+-----------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["example = flightData2015\\\n    .groupBy(\"DEST_COUNTRY_NAME\")\\\n    .sum(\"count\")\\\n    .withColumnRenamed(\"sum(count)\", \"destination_total\")\\\n    .sort(desc(\"destination_total\"))\\\n    .limit(5)\n\nexample.explain()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f8b23ab1-d604-4cf5-8b55-d2343a3ce331","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- TakeOrderedAndProject(limit=5, orderBy=[destination_total#141L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#55,destination_total#141L])\n   +- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[finalmerge_sum(merge sum#145L) AS sum(count#57)#137L])\n      +- Exchange hashpartitioning(DEST_COUNTRY_NAME#55, 1), ENSURE_REQUIREMENTS, [plan_id=282]\n         +- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[partial_sum(count#57) AS sum#145L])\n            +- FileScan csv [DEST_COUNTRY_NAME#55,count#57] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/definitive-guide/data/flight-data/csv/2015-s..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- TakeOrderedAndProject(limit=5, orderBy=[destination_total#141L DESC NULLS LAST], output=[DEST_COUNTRY_NAME#55,destination_total#141L])\n   +- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[finalmerge_sum(merge sum#145L) AS sum(count#57)#137L])\n      +- Exchange hashpartitioning(DEST_COUNTRY_NAME#55, 1), ENSURE_REQUIREMENTS, [plan_id=282]\n         +- HashAggregate(keys=[DEST_COUNTRY_NAME#55], functions=[partial_sum(count#57) AS sum#145L])\n            +- FileScan csv [DEST_COUNTRY_NAME#55,count#57] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/definitive-guide/data/flight-data/csv/2015-s..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,count:int>\n\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["staticDataFrame = spark.read.format(\"csv\")\\\n    .option(\"header\", \"true\")\\\n    .option(\"inferSchema\", \"true\")\\\n    .load(\"databricks-datasets/definitive-guide/data/retail-data/by-day/*.csv\")\n\nstaticDataFrame.createOrReplaceTempView(\"retail_data\")\nstaticSchema = staticDataFrame.schema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"28f9ce56-a182-41e3-a18d-11baed445ef4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["staticDataFrame.show(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7dca3152-51a1-404f-8d0c-3fb65b5e3b37","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\nonly showing top 3 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n|   580538|    23084|  RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n|   580538|    23077| DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n|   580538|    22906|12 MESSAGE CARDS ...|      24|2011-12-05 08:38:00|     1.65|   14075.0|United Kingdom|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\nonly showing top 3 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import window, col\n\n# 총 구매비용 칼럼을 추가하고 고객이 가장 많이 소비한 날 찾기\n\nstaticDataFrame\\\n    .selectExpr(\n        #\"CustomerId\",\n        \"(UnitPrice * Quantity) as total_cost\",\n        \"InvoiceDate\")\\\n    .groupBy(\n        #col(\"CustomerId\"), \n        window(col(\"InvoiceDate\"), \"1 day\"))\\\n    .sum(\"total_cost\")\\\n    .orderBy(col(\"sum(total_cost)\").desc())\\\n    .show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4c75a767-9f30-4453-982a-173f9937a77a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+------------------+\n|              window|   sum(total_cost)|\n+--------------------+------------------+\n|{2011-11-14 00:00...|112141.10999999996|\n|{2011-09-20 00:00...|109286.20999999993|\n|{2011-12-08 00:00...| 81417.77999999982|\n|{2011-11-23 00:00...|  78480.6999999997|\n|{2011-10-05 00:00...| 75244.42999999986|\n+--------------------+------------------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+------------------+\n|              window|   sum(total_cost)|\n+--------------------+------------------+\n|{2011-11-14 00:00...|112141.10999999996|\n|{2011-09-20 00:00...|109286.20999999993|\n|{2011-12-08 00:00...| 81417.77999999982|\n|{2011-11-23 00:00...|  78480.6999999997|\n|{2011-10-05 00:00...| 75244.42999999986|\n+--------------------+------------------+\nonly showing top 5 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# 스트리밍을 위한 코드로 수정하기\n\nstreamingDataFrame = spark.readStream\\\n    .schema(staticSchema)\\\n    .option(\"maxFilesPerTrigger\", 1)\\\n    .format(\"csv\")\\\n    .option(\"header\", \"true\")\\\n    .load(\"databricks-datasets/definitive-guide/data/retail-data/by-day/*.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dc4d5f2a-3a1d-493d-95f2-b49cb829aa53","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["streamingDataFrame.isStreaming"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48f047e0-0de0-4ebe-a0b1-54400a3c7078","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[29]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[29]: True"]}}],"execution_count":0},{"cell_type":"code","source":["purchaseByCustomerPerHour = streamingDataFrame\\\n    .selectExpr(\n        \"CustomerId\",\n        \"(UnitPrice * Quantity) as total_cost\",\n        \"InvoiceDate\")\\\n    .groupBy(\n        col(\"CustomerId\"), \n        window(col(\"InvoiceDate\"), \"1 day\"))\\\n    .sum(\"total_cost\")\\\n    .orderBy(col(\"sum(total_cost)\").desc())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f1d35a6e-27f8-48eb-b841-08888a5f5b4f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["purchaseByCustomerPerHour.writeStream\\\n    .format(\"console\")\\ # .foramt(memory) : 메모리에\n    .queryName(\"customer_purchases\")\\\n    .outputMode(\"complete\")\\\n    .start()\n\n# 스파크가 데이터를 처라하는 시점이 아닌 이벤트 시간에 따라 윈도우를 구성하는 방식을 사용함\n# 이를 통해 기존 스파크 스트리밍의 단점을 구조적 스트리밍으로 보완할 수 있음"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fdd0d746-89de-4269-a5e0-4da2b7070d14","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[38]: <pyspark.sql.streaming.query.StreamingQuery at 0x7fc21020ab80>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[38]: <pyspark.sql.streaming.query.StreamingQuery at 0x7fc21020ab80>"]}}],"execution_count":0},{"cell_type":"code","source":["staticDataFrame.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fec5cb5e-7f8c-401d-804e-9013e6b88f2b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: timestamp (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: double (nullable = true)\n |-- Country: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- InvoiceNo: string (nullable = true)\n |-- StockCode: string (nullable = true)\n |-- Description: string (nullable = true)\n |-- Quantity: integer (nullable = true)\n |-- InvoiceDate: timestamp (nullable = true)\n |-- UnitPrice: double (nullable = true)\n |-- CustomerID: double (nullable = true)\n |-- Country: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# 데이터 불러오기\nfrom pyspark.sql.functions import date_format, col\n\npreppedDataFrame = staticDataFrame\\\n    .na.fill(0)\\\n    .withColumn(\"day_of_week\", date_format(col(\"InvoiceDate\"), \"EEEE\"))\\\n    .coalesce(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ddc2de74-d1a2-4b37-aae7-b24fd1fbc2ef","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 학습, 테스트 데이터 셋 구분(TranValidationSplit, CrossValidator ..)\n\ntrainDataFrame = preppedDataFrame\\\n    .where(\"InvoiceDate < '2011-07-01'\")\ntestDataFrame = preppedDataFrame\\\n    .where(\"InvoiceDate >= '2011-07-01'\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"276dad31-d0d4-4247-8a0a-977556782218","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["trainDataFrame.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"66297c79-898b-45c1-9035-ff0a8eb03355","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[46]: 245903","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[46]: 245903"]}}],"execution_count":0},{"cell_type":"code","source":["testDataFrame.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7965afa2-d1b0-4f9e-b89a-5e4d4462dadd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[47]: 296006","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[47]: 296006"]}}],"execution_count":0},{"cell_type":"code","source":["# string to indexer\n\nfrom pyspark.ml.feature import StringIndexer\n\nindexer = StringIndexer()\\\n    .setInputCol(\"day_of_week\")\\\n    .setOutputCol(\"day_of_week_index\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7651140e-c220-4098-a244-939d3abb419c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# one-hot encoder 1, 0\n# sklearn과는 다르게 string to one-hot으로 바로 변환 불가능\n# 숫자로 바꿔준 후 해야함(setInputCol에 day_of_week이 아니라, day_of_week_index가 들어간 이유)\n\nfrom pyspark.ml.feature import OneHotEncoder\n\nencoder = OneHotEncoder()\\\n    .setInputCol(\"day_of_week_index\")\\\n    .setOutputCol(\"day_of_week_index_encoded\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"08f7e3e3-f1b8-43c1-96f4-b127475b0e93","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#spark의 머신러닝 알고리즘은 수치형 벡터 타입을 입력으로 사용\n\nfrom pyspark.ml.feature import VectorAssembler\n\nvectorAssembler = VectorAssembler()\\\n    .setInputCols([\"UnitPrice\", \"Quantity\", \"day_of_week_index_encoded\"])\\\n    .setOutputCol(\"features\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"228284d3-fb0a-4df1-9f3a-31822fd40176","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 파이프라인 설정\n\nfrom pyspark.ml import Pipeline\n\ntransformationPipeline = Pipeline()\\\n    .setStages([indexer, encoder, vectorAssembler])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c5d3f0e0-0425-4375-907a-164033d688ac","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 학습 데이터 pipeline 태우기\nfittedPipeline = transformationPipeline.fit(trainDataFrame)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b41eed91-ee2d-4b35-827b-5e1fa6667122","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 데이터 변환\ntransformedTraning = fittedPipeline.transform(trainDataFrame)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5d40fcb5-da6e-41ca-9fe0-a5cd83d5bef6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 캐싱 중간 변환된 데이터셋의 복사본을 메모리에 저장하고, 하이퍼 파라미터 튜닝값을 적용\ntransformedTraning.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"13919dde-5c4e-4644-942c-b623efee1804","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[75]: DataFrame[InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: timestamp, UnitPrice: double, CustomerID: double, Country: string, day_of_week: string, day_of_week_index: double, day_of_week_index_encoded: vector, features: vector]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[75]: DataFrame[InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: timestamp, UnitPrice: double, CustomerID: double, Country: string, day_of_week: string, day_of_week_index: double, day_of_week_index_encoded: vector, features: vector]"]}}],"execution_count":0},{"cell_type":"code","source":["# 모델 학습\n\nfrom pyspark.ml.clustering import KMeans\n\nkmeans = KMeans()\\\n    .setK(20)\\\n    .setSeed(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cbe2c725-d9ed-4fac-a8a8-4c88a2baa7db","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# 학습 전 알고리즘 명칭 : Algorithm\n# 학습 후 알고리즘 명칭 : AlgorithmModel\n\nkmModel = kmeans.fit(transformedTraning)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"51646b8d-1167-48c8-99db-d47fc826cddd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# kmModel.computeCost(transformedTraning)\n# conputeCost는 3.0이상 버전에서 사용되지 않음\n# sklean과 비슷한 느낌으로 실루엣 계수로 판단 가능\n\nfrom pyspark.ml.evaluation import ClusteringEvaluator\n\ntransformedTest = fittedPipeline.transform(testDataFrame)\npredictions = kmModel.transform(transformedTest)\n\n# Evaluate clustering by computing Silhouette score\nevaluator = ClusteringEvaluator()\n\nsilhouette = evaluator.evaluate(predictions)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0a41888d-e298-4923-bd18-75b8d2dcc4b8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(silhouette)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f0e3cd52-d436-43fe-82be-8c6917720ed2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"0.5427938390491533\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["0.5427938390491533\n"]}}],"execution_count":0},{"cell_type":"code","source":["# tutorial만 보자면, python np, pd 사용법이랑 크게 다르지는 않아보임\n# stream과 분산 처리가 추가된 느낌\n\n# 저수준 API RDD : 원시 데이터를 읽거나 다루는 용도로 RDD 사용 가능, 하지만 구조적 API를 사용하는 것이 좋음\n# 지금까지로는 numpy, pandas -> 구조적 API\n# python code -> 저수준 API 처럼 느껴짐\n\n# 더 공부해보면서 알아가자~"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8c0a2dc0-8a04-4bb3-906f-3b7bdf7006ad","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"spark tutorial","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3103419915815926}},"nbformat":4,"nbformat_minor":0}
