{"cells":[{"cell_type":"code","source":["# 구매 이력 데이터\n# 적은 수로 분할할 수 있도록 리파티셔닝 후, 캐시\n\ndf = spark.read.format('csv')\\\n    .option('header', 'true')\\\n    .option('inferSchema', 'true')\\\n    .load('/databricks-datasets/definitive-guide/data/retail-data/all/*.csv')\\\n    .coalesce(5)\n\ndf.cache()\ndf.createOrReplaceTempView(\"dfTable\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ef5168c0-0123-4d52-ae54-227b66c0e44e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# count는 트랜스포메이션이 아닌 액션\n# count는 크기 이외에도 메모리에 DataFrame 캐싱 작업을 수행하는 용도로도 쓰임\ndf.count() == 541909"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"498e8d42-f986-4dd3-984b-3a0d13105c5c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[2]: True","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[2]: True"]}}],"execution_count":0},{"cell_type":"code","source":["# 지연 연산으로 사용하는 count\n# count(*)은 null값을 포함하여 카운트함\n# count(column)은 null을 카운트하지 않음\nfrom pyspark.sql.functions import count\n\ndf.select(count(\"StockCode\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"acc7cef9-07a9-4a69-8cf3-bc2c91d0d471","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------------+\n|count(StockCode)|\n+----------------+\n|          541909|\n+----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------------+\n|count(StockCode)|\n+----------------+\n|          541909|\n+----------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# countDistinct : 고유 레코드 수를 확인하기\nfrom pyspark.sql.functions import countDistinct\n\ndf.select(countDistinct(\"StockCode\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"45a37d97-9264-4a45-af98-78b07cd5e7f3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-------------------------+\n|count(DISTINCT StockCode)|\n+-------------------------+\n|                     4070|\n+-------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------------------+\n|count(DISTINCT StockCode)|\n+-------------------------+\n|                     4070|\n+-------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# approx_count_distinct : 고유 레코드 수의 근사치 구하기\n# 최대 추정 오류율 파라미터가 들어가야 함\n\nfrom pyspark.sql.functions import approx_count_distinct\n\ndf.select(approx_count_distinct(\"StockCode\", 0.1)).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ba510562-745c-4515-900d-bcf3a7b8756b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+--------------------------------+\n|approx_count_distinct(StockCode)|\n+--------------------------------+\n|                            3364|\n+--------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------------------+\n|approx_count_distinct(StockCode)|\n+--------------------------------+\n|                            3364|\n+--------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# first, last : DataFrame의 첫번째, 마지막값 출력\n\nfrom pyspark.sql.functions import first, last\n\ndf.select(first(\"StockCode\"), last(\"StockCode\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1245fe66-a33f-4c8c-bf67-d41a34ded3fa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------------+---------------+\n|first(StockCode)|last(StockCode)|\n+----------------+---------------+\n|          85123A|          22138|\n+----------------+---------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------------+---------------+\n|first(StockCode)|last(StockCode)|\n+----------------+---------------+\n|          85123A|          22138|\n+----------------+---------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# min, max\n\nfrom pyspark.sql.functions import min, max\n\ndf.select(min(\"Quantity\"), max(\"Quantity\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b5e48899-a82c-48a5-9a26-466079cb89db","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-------------+-------------+\n|min(Quantity)|max(Quantity)|\n+-------------+-------------+\n|       -80995|        80995|\n+-------------+-------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+-------------+\n|min(Quantity)|max(Quantity)|\n+-------------+-------------+\n|       -80995|        80995|\n+-------------+-------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# sum\n\nfrom pyspark.sql.functions import sum\n\ndf.select(sum(\"Quantity\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eba22548-a874-42c4-9717-f048f6d1e443","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+-------------+\n|sum(Quantity)|\n+-------------+\n|      5176450|\n+-------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+\n|sum(Quantity)|\n+-------------+\n|      5176450|\n+-------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# sumDistinct\n\nfrom pyspark.sql.functions import sumDistinct\n\ndf.select(sumDistinct(\"Quantity\")).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bb4e1dd6-c342-4ade-8096-73977643d25d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"/databricks/spark/python/pyspark/sql/functions.py:386: FutureWarning: Deprecated in 3.2, use sum_distinct instead.\n  warnings.warn(\"Deprecated in 3.2, use sum_distinct instead.\", FutureWarning)\n+----------------------+\n|sum(DISTINCT Quantity)|\n+----------------------+\n|                 29310|\n+----------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/spark/python/pyspark/sql/functions.py:386: FutureWarning: Deprecated in 3.2, use sum_distinct instead.\n  warnings.warn(\"Deprecated in 3.2, use sum_distinct instead.\", FutureWarning)\n+----------------------+\n|sum(DISTINCT Quantity)|\n+----------------------+\n|                 29310|\n+----------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# avg, mean\nfrom pyspark.sql.functions import sum, count, avg, expr\n\ndf.select(\n    count(\"Quantity\").alias(\"count\"),\n    sum(\"Quantity\").alias(\"sum\"),\n    avg(\"Quantity\").alias(\"avg\"),\n    expr(\"mean(Quantity)\").alias(\"mean\")\n).selectExpr(\n    \"sum/count\",\n    \"avg\",\n    \"mean\"\n).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2d37c30a-da09-4f6d-ad1c-05e0ede46c02","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------------+----------------+----------------+\n|   (sum / count)|             avg|            mean|\n+----------------+----------------+----------------+\n|9.55224954743324|9.55224954743324|9.55224954743324|\n+----------------+----------------+----------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------------+----------------+----------------+\n|   (sum / count)|             avg|            mean|\n+----------------+----------------+----------------+\n|9.55224954743324|9.55224954743324|9.55224954743324|\n+----------------+----------------+----------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e6f159da-000f-4491-b0b5-d2fde0d5fc3b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"spark ch.7","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4316894111695259}},"nbformat":4,"nbformat_minor":0}
